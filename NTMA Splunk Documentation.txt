Network Traffic Monitoring and Analysis Project
Splunk Documentation


Splunk Enterprise Install and Setup:

To set up monitoring with live traffic being forwarded, the free trial of Splunk enterprise was sufficient for the purpose of our project. Splunk enterprise will be set up on one instance called our monitor instance, and the forwarder will be set up on another one called our victim instance. The first step is to copy the wget link for Splunk enterprise and use this to get around having to enter a business email. Something like "10-minute mail" would also work for this purpose. The wget link avoids you having to input an email at all. After this, we used the following commands to download and extract the file to the correct location within the filesystem.

sudo wget -O splunk.tgz https://download.splunk.com/products/splunk/releases/9.4.3/linux/splunk-9.4.3-237ebbd22314-linux-amd64.tgz
sudo tar -xvzf splunk.tgz -C /opt

From here, Splunk now lives within the /opt directory. To operate Splunk, you either need to specify the full path to Splunk or be operating within the path. The full path for this case would be /opt/splunk/bin. To start Splunk this way, use:

sudo /opt/splunk/bin/splunk start

To operate from within the path:
cd /opt/splunk/bin
sudo ./splunk start

This is all we need to do from the CLI for the enterprise setup.
The practice of operating from within the path will be more helpful to keep from having to type more for the forwarder install because more command-line work will have to be done for that.

Our specific AWS instance did not come with a desktop interface preinstalled, so we had to download and configure one; luckily, this was easy enough. We chose to use xfce4, which is a lightweight desktop installation which is all we really needed for our purpose. To do this, run the following commands:

sudo apt update
sudo apt install xfce4 xfce4-goodies -y

This installs the desktop and a collection of functionality features.
We then needed to have some way to connect to the desktop and landed on Remote Desktop Protocol(RDP) as a solution. To do this, we needed to install and configure xrdp. For this, run the following commands:

sudo apt install xrdp -y
sudo systemctl enable xrdp
sudo systemctl start xrdp
echo xfce4-session > ~/.xsession

This installs, enables, and starts xrdp. xrdp by default doesn't know which desktop to start up, so the last command tells xrdp to use xfce4 when someone connects through RDP.

The firewall may need to be configured to allow RDP connections. This can be done simply using the following commands:

sudo ufw allow 3389/tcp
sudo ufw reload

This allows tcp connections over port 3389, which is the default port for RDP connections, and then restarts the firewall for the changes to take effect. From here, just restart xrdp to finalize configuration using:

sudo systemctl restart xrdp

In our case, using AWS to manage these instances, we went into our security group for the monitor instance and added a rule to allow tcp on port 3389 and then restarted xrdp.

This would also be a good time, if your instance did not have a preconfigured password, to change your password or create users that each person who needs access can operate under when connecting.

You can then use the Remote Desktop Connection from a Windows machine. To do this, enter the public IP of the monitor instance, followed by a ":" and port 3389 in this syntax:

34.236.143.28:3389

This can be done with the private IP if you are on the same network. In our case, our instances were connected on a virtual network, so we had to use the public IP. If you are doing this within a company, in the case of remote work, port forwarding will need to be set up, as the public IP will not be assigned to an individual endpoint but rather the router.

Once connected, on a web browser, navigate to http://localhost:8000
This connects you to Splunk on port 8000. This is only after Splunk fully starts.
You will then have to log in with whatever credentials you chose during installation.
From here, click on settings, forwarding and receiving, configure receiving, new receiving port, type 9997, and finally click save. This will set up Splunk to listen for data on port 9997 which is Splunk's default receiving port.


Splunk Forwarder Install and Setup:

The Splunk universal forwarded is going to need to be set up on just one machine for our purpose but this setup can span across as many as you need for your purpose. We set this up on our victim instance to act as a possible target for an attack. The wget link will need to be copied for this as well but you will need to find the specific one for your OS. The one we used was for a Linux OS. On the endpoint that will be forwarding logs run the following commands:

cd /tmp
sudo wget -O splunkforwarder-10.0.1-c486717c322b-linux-amd64.tgz "https://download.splunk.com/products/universalforwarder/releases/10.0.1/linux/splunkforwarder-10.0.1-c486717c322b-linux-amd64.tgz"
sudo mv splunkforwarder-10.0.1-c486717c322b-linux-amd64.tgz /opt
cd /opt
sudo tar -xvzf splunkforwarder-10.0.1-c486717c322b-linux-amd64.tgz

These commands essentially accomplish the same thing as for the Enterprise install just with a different approach. The enterprise approach from the first step involves downloading Splunk in whatever the current working directory is and then extracting Splunk in the /opt directory. The approach for the above command for the forwarder involves downloading Splunk in the /tmp directory and then moving the zipped file to /opt. The file is then extracted from there.

From here, run:

cd /opt/splunkforwarder/bin
sudo ./splunk enable boot-start
sudo ./splunk start --accept-license

These commands allow Splunk to start when the machine starts up and then starts Splunk while accepting the license.

We will now begin setting up the forwarder by picking which logs to forward and where to forward them to. To accomplish this, we need to add a forwarding server and choose to monitor certain logs. These could be any logs but the ones we chose we /var/log, /var/log/auth.log, and /var/log/nginx/access.log.

sudo ./splunk add forward-server 34.236.143.28:9997
sudo ./splunk add monitor /var/log
sudo ./splunk add monitor /var/log/auth.log
sudo ./splunk add monitor /var/log/nginx/access.log

The first command chooses where to forward logs to. The IP is the public IP for the monitor machine, which is running Splunk enterprise. In our case, the monitor instance and the endpoint that we were monitoring are on the same network, so we could have used the private IPv4 as well. The ":9997" is deciding which port to send data on, which should match the listening port that we chose for the monitor instance. The next three commands all add different log files or directories to the list of forwarded logs. auth.log contains logs like SSH attempts, sudo use, root use, account access, among other things. The nginx/access.log is a web server that we set up with nginx to capture access attempts to the website. You will then need to restart the forwarder for these changes to take effect. Do this by running:

sudo ./splunk restart

***It should be noted that it is not best practice to use sudo when starting Splunk because it allows Splunk to run as root. This violates the principle of least privilege. This means that if Splunk were ever compromised, the attacker would automatically have root access. We did this for the simplicity of our demonstration to avoid any potential permissions issues.***

Splunk enterprise should now be running and listening on the monitor instance, and the Splunk universal forwarder should be running and forwarding logs to the monitor instance from the victim instance.

Now, use remote desktop connection to connect back into the Splunk monitor instance and log in to Splunk on the web browser. From here you can use the Search and Reporting application to search through your logs and create visual representations of your logs. We used ours to specifically flag and alert on SSH attempts, both successful and unsuccessful. We also chose to throw an alert when someone switched users to root as this should not need to happen for an average user. This would imply some privilege escalation in a real environment or an admin making changes. Either case warrants an alert.

To set up these alerts, in search and reporting, we searched for "index=* sshd Accepted". This shows any logs in which the ssh daemon allowed someone to connect successfully. From there, click on "Save As" and then "alert". You can configure this alert to do whatever you need it to do but we chose to have it throw a log event with "SSH Connection Made" and also add it to the triggered alerts tab within Splunk. We had it monitor in real-time and set the severity to critical in the case of SSH connections not being expected. We then did the same process for a failed SSH logins that used the wrong key. We also added an alert for when someone switched to the root user as this almost never needs to happen.

For the dashboard, we tracked web traffic requests to our nginx server by number or requests and then also the top ten IP addresses that requested the page. We also tracked sudo use, filter by top ten command ran using sudo and alerts when sudo su was run. We added another panel for SSH connections sorted by IP which in our case was only five different IPs. The top panel of our dashboard was set up for alerts which updated every time an alert was triggered and sorted them by alert type. All of this together gave us a dashboard that was easy to understand and fit the needs of our demonstration.